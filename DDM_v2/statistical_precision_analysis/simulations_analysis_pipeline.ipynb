{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7a607f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module://matplotlib_inline.backend_inline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QSocketNotifier: Can only be used with threads started with QThread\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qt5agg\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import dill\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from hmmlearn import hmm, vhmm\n",
    "\n",
    "from synthetic_data_generation_functions import *\n",
    "from synthetic_data_analysis_functions import *\n",
    "from hmm_functions import *\n",
    "\n",
    "\n",
    "plt.style.use('/home/david/Documents/code/phd/paper.mplstyle')\n",
    "\n",
    "print(plt.get_backend())\n",
    "%matplotlib qt5\n",
    "print(plt.get_backend())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3965290c",
   "metadata": {},
   "source": [
    "# Simulations generations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b03673",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f7e76c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_number = 100\n",
    "noise_amplitude = 0.1\n",
    "delta = 0.05\n",
    "drift = 0.0\n",
    "p_a = 0.5\n",
    "p_a_reward = 0.8\n",
    "p_b_reward = 0\n",
    "\n",
    "number_of_simulations_perset = 20\n",
    "\n",
    "n_simulations_list = [number_of_simulations_perset]*100\n",
    "\n",
    "start_index = 0\n",
    "\n",
    "simulations_folder_path = '/home/david/Documents/code/DDM_v2_synthetic_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c76d6b5",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e206d078",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generate_simulations = False\n",
    "\n",
    "for i, n_simulations in enumerate(n_simulations_list):\n",
    "    \n",
    "    if not(generate_simulations):\n",
    "\n",
    "        break\n",
    "\n",
    "    simulations_batch = run_simulations_batch(p_a, p_a_reward, p_b_reward, steps_number, noise_amplitude, delta, drift, n_simulations)\n",
    "\n",
    "    with open(f'{simulations_folder_path}/n_{n_simulations}/simulations_batch_{n_simulations}_test_{i+1}.pkl', 'wb') as file:\n",
    "        dill.dump(simulations_batch, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72bdce77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_average_probability_sequences = generate_test_average_probability_sequences(delta_range, args)\n",
    "\n",
    "# with open(f'DDM_v2/statistical_precision_analysis/simulations_batches/test_average_probability_sequences.pkl', 'wb') as file:\n",
    "#     dill.dump(test_average_probability_sequences, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83ad6fd",
   "metadata": {},
   "source": [
    "# HMM fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e1da21",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "646b4a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_to_test = np.arange(2,16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f54e97d",
   "metadata": {},
   "source": [
    "## Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebdcf6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_model = False # PARAM\n",
    "\n",
    "if fit_model:\n",
    "\n",
    "    for index, n_simulations in enumerate(tqdm(n_simulations_list)):\n",
    "\n",
    "        ####################\n",
    "        ### Loading Data ###\n",
    "        ####################\n",
    "\n",
    "        with open(f'{simulations_folder_path}/n_{n_simulations}/simulations_batch_{n_simulations}_test_{start_index + index+1}.pkl', 'rb') as file:\n",
    "            synthetic_data = dill.load(file)\n",
    "\n",
    "        ########################\n",
    "        ### Reformating Data ###\n",
    "        ########################\n",
    "\n",
    "        slice_size = int(n_simulations/2)\n",
    "\n",
    "        training_data = [synthetic_data[i]['choices'] for i in np.arange(0,slice_size)]\n",
    "        validation_data = [synthetic_data[i]['choices'] for i in np.arange(slice_size,2*slice_size)]\n",
    "\n",
    "\n",
    "        training_emissions = np.array([]).astype(int)\n",
    "        validation_emissions = np.array([]).astype(int)\n",
    "\n",
    "        for x,y in zip(training_data,validation_data):\n",
    "\n",
    "            training_emissions = np.concatenate((training_emissions, x))\n",
    "            validation_emissions = np.concatenate((validation_emissions, y))\n",
    "\n",
    "        training_emissions = training_emissions.reshape(-1,1)\n",
    "        training_emissions_lengths = [len(x) for x in training_data]\n",
    "\n",
    "        validation_emissions = validation_emissions.reshape(-1,1)\n",
    "        validation_emissions_lengths = [len(y) for y in validation_data]\n",
    "\n",
    "        ###################\n",
    "        ### Infer model ###\n",
    "        ###################\n",
    "\n",
    "        best_model, best_score = infer_best_model_score(training_emissions, validation_emissions, \n",
    "                                                training_emissions_lengths, validation_emissions_lengths, \n",
    "                                                n_to_test, leave_loading_bar=False, verbose=False)\n",
    "        \n",
    "        ##################\n",
    "        ### Save model ###\n",
    "        ##################\n",
    "        \n",
    "        with open(f'{simulations_folder_path}/n_{n_simulations}/best_model_score_{n_simulations}_test_{start_index + index+1}.pkl', 'wb') as file:\n",
    "            dill.dump(best_model, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd3f8e2",
   "metadata": {},
   "source": [
    "# Drift Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66398f9",
   "metadata": {},
   "source": [
    "## Generating \"theoretical\" average probability sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35ab4690",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_theoretical_sequences = False # PARAM\n",
    "\n",
    "if generate_theoretical_sequences:\n",
    "\n",
    "    args = synthetic_data[0]['parameters'] + [5000]\n",
    "    delta_range = np.linspace(0.01,0.2,200)\n",
    "\n",
    "\n",
    "    test_average_probability_sequences = generate_test_average_probability_sequences(delta_range, args)\n",
    "\n",
    "    with open(f'{simulations_folder_path}/test_average_probability_sequences.pkl', 'wb') as file:\n",
    "        dill.dump([delta_range, test_average_probability_sequences], file)\n",
    "\n",
    "else:\n",
    " \n",
    "    with open(f'{simulations_folder_path}/test_average_probability_sequences.pkl', 'rb') as file:\n",
    "        delta_range, test_average_probability_sequences = dill.load(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57683e2",
   "metadata": {},
   "source": [
    "## Minimizing mean square error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e85d23c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5951dd6690824a08bd21ee8d1d18ebbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_result = False # PARAM\n",
    "average_proba_sequences_hmm = []\n",
    "\n",
    "\n",
    "for index, _ in enumerate(tqdm(n_simulations_list)):\n",
    "# for index, _ in enumerate(n_simulations_list):\n",
    "\n",
    "    ##############################\n",
    "    ### Loading Data and Model ###\n",
    "    ##############################\n",
    "\n",
    "    with open(f'{simulations_folder_path}/n_{n_simulations}/simulations_batch_{n_simulations}_test_{start_index + index+1}.pkl', 'rb') as file:\n",
    "        synthetic_data = dill.load(file)\n",
    "\n",
    "    with open(f'{simulations_folder_path}/n_{n_simulations}/best_model_score_{n_simulations}_test_{start_index + index+1}.pkl', 'rb') as file:\n",
    "        model = dill.load(file)\n",
    "\n",
    "    ########################\n",
    "    ### Reformating Data ###\n",
    "    ########################\n",
    "\n",
    "    test_data = [synth_data['choices'] for synth_data in synthetic_data]\n",
    "\n",
    "    initial_state_list = []\n",
    "    sequences_number = len(test_data)\n",
    "\n",
    "    for i in range(sequences_number):\n",
    "        \n",
    "        choices_sequence = test_data[i]\n",
    "        \n",
    "        states_sequence = model.predict(np.int16(choices_sequence.reshape(-1,1)))\n",
    "        initial_state_list.append(states_sequence[0])\n",
    "\n",
    "    initial_state_list_distri = []\n",
    "\n",
    "    for s in range(len(model.transmat_)):\n",
    "\n",
    "        initial_state_list_distri.append(initial_state_list.count(s))\n",
    "\n",
    "    transmat = model.transmat_\n",
    "    emission_vect = model.emissionprob_[:,1]\n",
    "    mat = transmat\n",
    "    sorted_indexes = np.argsort(emission_vect)\n",
    "    vector = np.ones([len(transmat),1])/len(transmat)\n",
    "\n",
    "    ##\n",
    "\n",
    "    new_transmat = order_matrix(mat, sorted_indexes)\n",
    "\n",
    "    ##\n",
    "\n",
    "    new_emissionmat = []\n",
    "    new_initial_state_list_distri = []\n",
    "\n",
    "    for i in sorted_indexes:\n",
    "        new_emissionmat.append(model.emissionprob_[i,:])\n",
    "        new_initial_state_list_distri.append(initial_state_list_distri[i])\n",
    "\n",
    "    new_emissionmat = np.array(new_emissionmat)\n",
    "    new_initial_state_list_distri = np.array(new_initial_state_list_distri)/np.sum(new_initial_state_list_distri)\n",
    "\n",
    "\n",
    "    ####################\n",
    "    ### Computations ###\n",
    "    ####################\n",
    "\n",
    "    average_proba_sequence_hmm = []\n",
    "\n",
    "    steps = np.arange(len(test_data[0]))\n",
    "    new_mat_i = new_transmat\n",
    "\n",
    "    for i in steps:\n",
    "\n",
    "        new_mat_i = np.matmul(new_mat_i,new_transmat)\n",
    "        res = np.matmul(new_initial_state_list_distri,new_mat_i)*new_emissionmat[:,1]\n",
    "            \n",
    "        average_proba_sequence_hmm.append(np.sum(res))\n",
    "\n",
    "    average_proba_sequences_hmm.append(average_proba_sequence_hmm)\n",
    "\n",
    "    if not(save_result):\n",
    "\n",
    "        continue\n",
    "\n",
    "    mse_list = []\n",
    "\n",
    "    for test_average_probability_sequence in tqdm(test_average_probability_sequences, leave=False):\n",
    "    # for test_average_probability_sequence in test_average_probability_sequences:\n",
    "\n",
    "        mse_list.append(compute_mean_square_error_v2(average_proba_sequence_hmm, test_average_probability_sequence))\n",
    "\n",
    "    min_mse = np.min(mse_list)\n",
    "    recovered_delta = delta_range[np.where(mse_list==min_mse)[0]]\n",
    "\n",
    "    ##############################\n",
    "    ### Saving Recovered Delta ###\n",
    "    ##############################\n",
    "    \n",
    "    with open(f'{simulations_folder_path}/n_{n_simulations}/recovered_delta_{n_simulations}_{start_index + index+1}.pkl', 'wb') as file:\n",
    "        dill.dump([test_average_probability_sequence,recovered_delta], file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7137207b",
   "metadata": {},
   "source": [
    "# Mean square error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3a142d",
   "metadata": {},
   "source": [
    "## Recovered delta loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32808007",
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered_delta_list = []\n",
    "\n",
    "for index, _ in enumerate(n_simulations_list):\n",
    "\n",
    "    with open(f'{simulations_folder_path}/n_{n_simulations}/recovered_delta_{n_simulations}_{start_index + index+1}.pkl', 'rb') as file:\n",
    "        _, recovered_delta = dill.load(file)\n",
    "    \n",
    "    recovered_delta_list.append(recovered_delta[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f6097b",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "730ec41d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Recovered drift')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig=plt.figure(figsize=(1, 4), dpi=300, constrained_layout=False, facecolor='w')\n",
    "gs = fig.add_gridspec(1, 1)\n",
    "row = gs[:].subgridspec(1, 1, hspace=0.5)\n",
    "\n",
    "ax1 = plt.subplot(row[0,0])\n",
    "\n",
    "ax1.scatter(np.ones(len(n_simulations_list)), recovered_delta_list, marker='s', alpha=0.01, s=3, linewidth=0)\n",
    "\n",
    "ax1.axhline(0.05, linewidth=0.7, color='k', linestyle='--', label='Drift to recover')\n",
    "\n",
    "ax1.set_title(f'{len(n_simulations_list)} sets of {number_of_simulations_perset} simulations of length {steps_number}')\n",
    "\n",
    "ax1.set_xticks([])\n",
    "ax1.set_ylabel('Recovered drift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd96ed19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe80448bdd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig=plt.figure(figsize=(4, 4), dpi=300, constrained_layout=False, facecolor='w')\n",
    "gs = fig.add_gridspec(1, 1)\n",
    "row = gs[:].subgridspec(1, 1, hspace=0.5)\n",
    "\n",
    "ax1 = plt.subplot(row[0,0])\n",
    "\n",
    "histo = np.histogram(recovered_delta_list, bins=np.linspace(0.01,0.2,51), density=True)\n",
    "bin_width = histo[1][1] - histo[1][0]\n",
    "ax1.stairs(histo[0]/np.sum(histo[0])/bin_width, histo[1], alpha=0.5, fill=True, label = 'Recovered drift probability density')\n",
    "\n",
    "x = np.linspace(-0.2,0.2)\n",
    "sigma = 0.1\n",
    "ax1.plot(x, np.exp(-x**2/(2*sigma**2)) * 1/np.sqrt(2*sigma**2*np.pi), label = \"Noise probability density\")\n",
    "\n",
    "ax1.axvline(0.05, linewidth=0.7, color='k', linestyle='--', label='Drift to recover')\n",
    "\n",
    "# ax1.set_xticks([])\n",
    "ax1.set_title(f'{len(n_simulations_list)} sets of {number_of_simulations_perset} simulations of length {steps_number}')\n",
    "\n",
    "ax1.set_ylim([0,None])\n",
    "ax1.set_xlabel('Recovered drift')\n",
    "ax1.set_ylabel('Probability density')\n",
    "\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e5da019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Number of simulations sets')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig=plt.figure(figsize=(1, 4), dpi=300, constrained_layout=False, facecolor='w')\n",
    "gs = fig.add_gridspec(1, 1)\n",
    "row = gs[:].subgridspec(1, 1, hspace=0.5)\n",
    "\n",
    "ax1 = plt.subplot(row[0,0])\n",
    "\n",
    "histo = np.histogram(recovered_delta_list, bins=np.linspace(0.01,0.2,51), density=False)\n",
    "ax1.stairs(histo[0], histo[1], alpha=0.5, fill=True)\n",
    "ax1.axvline(0.05, linewidth=0.7, color='k', linestyle='--', label='Drift to recover')\n",
    "\n",
    "# ax1.set_xticks([])\n",
    "ax1.set_title(f'{len(n_simulations_list)} sets of {number_of_simulations_perset} simulations of length {steps_number}')\n",
    "\n",
    "ax1.set_ylim([0,None])\n",
    "ax1.set_xlabel('Recovered drift')\n",
    "ax1.set_ylabel('Number of simulations sets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9537465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe801db4470>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig=plt.figure(figsize=(4, 4), dpi=300, constrained_layout=False, facecolor='w')\n",
    "gs = fig.add_gridspec(1, 1)\n",
    "row = gs[:].subgridspec(1, 1, hspace=0.5)\n",
    "\n",
    "\n",
    "ax1 = plt.subplot(row[0,0])\n",
    "\n",
    "index_simu_to_plot = 6\n",
    "\n",
    "ax1.plot(average_proba_sequences_hmm[index_simu_to_plot], label='Average probability infered by HMM', color='black')\n",
    "\n",
    "delta_range_to_plot = [(i,delta_range[i]) for i in range(0, len(delta_range), 42)]\n",
    "\n",
    "for i, d in delta_range_to_plot:\n",
    "\n",
    "    ax1.plot(test_average_probability_sequences[i], label=f'Average probability of 5000 simu. with drift={np.round(d,4)}', alpha=0.5, linestyle='--')\n",
    "\n",
    "# ax1.axvline(0.05, linewidth=0.7, color='k', linestyle='--', label='Drift to recover')\n",
    "\n",
    "# ax1.set_xticks([])\n",
    "ax1.set_title(f'Set of {number_of_simulations_perset} simulations of length {steps_number}\\n True drift: {delta}, Recovered drift: {np.round(recovered_delta_list[index_simu_to_plot],4)}')\n",
    "\n",
    "ax1.set_xlabel('Step')\n",
    "ax1.set_ylabel('Average probability to do CW')\n",
    "\n",
    "ax1.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
